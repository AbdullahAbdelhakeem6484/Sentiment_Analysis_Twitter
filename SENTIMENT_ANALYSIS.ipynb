{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90fafff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################\n",
    "# Author        : - Abdullah Abdelhakeem                                                                                       #  \n",
    "# Date          : - 24-9-2021                                                                                                  #  \n",
    "# Version       : - v 0.0.1                                                                                                    #  \n",
    "# Project       : - Real Time Streaming Sentiment Analysis (+ve , -ve , N) Twitter.                                                    #  \n",
    "#                                                                                                                              # \n",
    "# Dependencies  : -   1- Tweepy            \n",
    "#                     2- Apache Kafka      \n",
    "#                     3- Apache Spark      \n",
    "#                     4- kafka-python      \n",
    "#                     5- pySpark           \n",
    "#                     6- Delta Lake package                                                                                                         \n",
    "#\n",
    "#\n",
    "#\n",
    "#                                                                                                                              #\n",
    "# Steps :                                                                                                                      # \n",
    "#        1- install Dependency                                                                                                 # \n",
    "#        2- Load Data                                                                                                          # \n",
    "#        3- Cleaning the Data                                                                                                  # \n",
    "#        4- PreProcessing the Data                                                                                             # \n",
    "#        5- Feature Selection                                                                                                  # \n",
    "#        6- Tokenize the data                                                                                               # \n",
    "#        7- Split the data \n",
    "#        8- Create an ML Pipeline\n",
    "#        9- tarin the model(fit) and predict\n",
    "#        10-Calculate Accuracy\n",
    "#        11-save the model for deploying\n",
    "#        12-load the model saved(check)\n",
    "#                                                                                                                              #\n",
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3163c680",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################ \n",
    "#                                                                                                                              #\n",
    "# Requirements :                                                                                                               # \n",
    "#        1- Tweepy                                                                                                             # \n",
    "#        2- Apache Kafka                                                                                                       # \n",
    "#        3- Apache Spark                                                                                                       # \n",
    "#        4- kafka-python                                                                                                       # \n",
    "#        5- pySpark                                                                                                            # \n",
    "#        6- Delta Lake package                                                                                                 # \n",
    "#                                                                                                                              # \n",
    "#                                                                                                                              #          \n",
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93383927",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reads 'Sentiment140' dataset, trains and saves the pipeline \n",
    "using SparkML\n",
    "'''\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "from pyspark.sql.functions import udf\n",
    "import re\n",
    "\n",
    "from pyspark.ml.feature import CountVectorizer, IDF\n",
    "from pyspark.ml.feature import StopWordsRemover, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pathlib import Path\n",
    "\n",
    "from pyspark.sql.types import StringType, StructType, StructField, ArrayType\n",
    "from pyspark.sql.functions import udf, from_json, col\n",
    "\n",
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from tweepy import OAuthHandler, StreamListener\n",
    "from tweepy import Stream, API\n",
    "# from kafka import KafkaProducer\n",
    "\n",
    "import json\n",
    "from dateutil.parser import parse\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe1e975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Include information necessary for Twitter API authentication\n",
    "# Developer Account Take 15 days\n",
    "# access_token = 'ACCESS_TOKEN'\n",
    "# access_token_secret = 'ACCESS_TOKEN_SECRET'\n",
    "# consumer_key = 'CONSUMER_KEY'\n",
    "# consumer_secret = 'CONSUMER_SECRET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a958986d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1e9b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('local[*]').appName(\"RDDApp\").getOrCreate()\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc =spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8506369",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlcontext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf73d663",
   "metadata": {},
   "source": [
    "# Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ac4f056",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Sentiment Analysis dataset\n",
    "0 - the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "1 - the id of the tweet \n",
    "2 - the date of the tweet \n",
    "3 - the query . If there is no query, then this value is NO_QUERY.\n",
    "4 - the user that tweeted \n",
    "5 - the text of the tweet \n",
    "'''\n",
    "\n",
    "raw_data = sqlcontext \\\n",
    "    .read \\\n",
    "    .format('csv') \\\n",
    "    .options(header=False) \\\n",
    "    .load(\"train.csv\") \\\n",
    "    .selectExpr(\"_c0 as sentiment\",\"_c1 as id\",\"_c2 as date \",\"_c3 as query\",\"_c4 as user\",\"_c5 as message\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "989a04d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+--------+---------------+--------------------+\n",
      "|sentiment|        id|                date|   query|           user|             message|\n",
      "+---------+----------+--------------------+--------+---------------+--------------------+\n",
      "|        0|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n",
      "|        0|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|        0|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|        0|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|        0|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|        0|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|        0|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug |\n",
      "|        0|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|        0|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|        0|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "|        0|1467812416|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...|\n",
      "|        0|1467812579|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...|\n",
      "|        0|1467812723|Mon Apr 06 22:20:...|NO_QUERY|           TLeC|@caregiving I cou...|\n",
      "|        0|1467812771|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|@octolinz16 It it...|\n",
      "|        0|1467812784|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...|\n",
      "|        0|1467812799|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|\n",
      "|        0|1467812964|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|Hollis' death sce...|\n",
      "|        0|1467813137|Mon Apr 06 22:20:...|NO_QUERY|       armotley|about to file taxes |\n",
      "|        0|1467813579|Mon Apr 06 22:20:...|NO_QUERY|     starkissed|@LettyA ahh ive a...|\n",
      "|        0|1467813782|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "+---------+----------+--------------------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "010ffb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sentiment: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- query: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "094d6f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlcontext \\\n",
    "    .read \\\n",
    "    .format('csv') \\\n",
    "    .options(header=False) \\\n",
    "    .load(\"train.csv\") \\\n",
    "    .selectExpr(\"_c0 as sentiment\", \"_c5 as message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "463c1e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|sentiment|             message|\n",
      "+---------+--------------------+\n",
      "|        0|@switchfoot http:...|\n",
      "|        0|is upset that he ...|\n",
      "|        0|@Kenichan I dived...|\n",
      "|        0|my whole body fee...|\n",
      "|        0|@nationwideclass ...|\n",
      "|        0|@Kwesidei not the...|\n",
      "|        0|         Need a hug |\n",
      "|        0|@LOLTrish hey  lo...|\n",
      "|        0|@Tatiana_K nope t...|\n",
      "|        0|@twittera que me ...|\n",
      "|        0|spring break in p...|\n",
      "|        0|I just re-pierced...|\n",
      "|        0|@caregiving I cou...|\n",
      "|        0|@octolinz16 It it...|\n",
      "|        0|@smarrison i woul...|\n",
      "|        0|@iamjazzyfizzle I...|\n",
      "|        0|Hollis' death sce...|\n",
      "|        0|about to file taxes |\n",
      "|        0|@LettyA ahh ive a...|\n",
      "|        0|@FakerPattyPattz ...|\n",
      "+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68fb766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d398a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e98da38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47fe608c",
   "metadata": {},
   "source": [
    "# Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fa43ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process = udf(\n",
    "    lambda x: re.sub(r'[^A-Za-z\\n ]|(http\\S+)|(www.\\S+)', '', \\\n",
    "        x.lower().strip()).split(), ArrayType(StringType())\n",
    "    )\n",
    "df = df.withColumn(\"cleaned_data\", pre_process(df.message)).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a366f239",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+\n",
      "|sentiment|             message|        cleaned_data|\n",
      "+---------+--------------------+--------------------+\n",
      "|        0|@switchfoot http:...|[switchfoot, awww...|\n",
      "|        0|is upset that he ...|[is, upset, that,...|\n",
      "|        0|@Kenichan I dived...|[kenichan, i, div...|\n",
      "|        0|my whole body fee...|[my, whole, body,...|\n",
      "|        0|@nationwideclass ...|[nationwideclass,...|\n",
      "|        0|@Kwesidei not the...|[kwesidei, not, t...|\n",
      "|        0|         Need a hug |      [need, a, hug]|\n",
      "|        0|@LOLTrish hey  lo...|[loltrish, hey, l...|\n",
      "|        0|@Tatiana_K nope t...|[tatianak, nope, ...|\n",
      "|        0|@twittera que me ...|[twittera, que, m...|\n",
      "|        0|spring break in p...|[spring, break, i...|\n",
      "|        0|I just re-pierced...|[i, just, repierc...|\n",
      "|        0|@caregiving I cou...|[caregiving, i, c...|\n",
      "|        0|@octolinz16 It it...|[octolinz, it, it...|\n",
      "|        0|@smarrison i woul...|[smarrison, i, wo...|\n",
      "|        0|@iamjazzyfizzle I...|[iamjazzyfizzle, ...|\n",
      "|        0|Hollis' death sce...|[hollis, death, s...|\n",
      "|        0|about to file taxes |[about, to, file,...|\n",
      "|        0|@LettyA ahh ive a...|[lettya, ahh, ive...|\n",
      "|        0|@FakerPattyPattz ...|[fakerpattypattz,...|\n",
      "+---------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8103602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.select('cleaned_data').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9d252d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16fbefd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8f8f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b814564d",
   "metadata": {},
   "source": [
    "# Split the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b222518",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.8,0.2],seed = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "371fd3d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+\n",
      "|sentiment|             message|        cleaned_data|\n",
      "+---------+--------------------+--------------------+\n",
      "|        0|           FUCK YOU!|         [fuck, you]|\n",
      "|        0|          i want ...|[i, want, some, b...|\n",
      "|        0|        my head f...|[my, head, feels,...|\n",
      "|        0|      My current ...|[my, current, hea...|\n",
      "|        0|      this weeken...|[this, weekend, h...|\n",
      "|        0|            #canucks|           [canucks]|\n",
      "|        0|     &lt;- but mu...|[lt, but, mustach...|\n",
      "|        0|     I dont like ...|[i, dont, like, t...|\n",
      "|        0|     I'll get on ...|[ill, get, on, it...|\n",
      "|        0|     ok thats it ...|[ok, thats, it, y...|\n",
      "|        0|     what the fuc...|[what, the, fuccc...|\n",
      "|        0|    I just cut my...|[i, just, cut, my...|\n",
      "|        0|    on the comput...|[on, the, compute...|\n",
      "|        0|       wompppp wompp|    [wompppp, wompp]|\n",
      "|        0|   *old me's dead...|[old, mes, dead, ...|\n",
      "|        0|   ...  Headed to...|[headed, to, hosp...|\n",
      "|        0|   BoRinG   ): wh...|[boring, whats, w...|\n",
      "|        0|   I hate it when...|[i, hate, it, whe...|\n",
      "|        0|   I want to disp...|[i, want, to, dis...|\n",
      "|        0|   IN an effort t...|[in, an, effort, ...|\n",
      "+---------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f754795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "def spark_shape(self):\n",
    "    return (self.count(), len(self.columns))\n",
    "pyspark.sql.dataframe.DataFrame.shape = spark_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47672ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1279865, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699e4b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d565d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+\n",
      "|sentiment|             message|        cleaned_data|\n",
      "+---------+--------------------+--------------------+\n",
      "|        0|       i really2 ...|[i, really, dont,...|\n",
      "|        0|     jb isnt show...|[jb, isnt, showin...|\n",
      "|        0|    Not feeling i...|[not, feeling, it...|\n",
      "|        0|   Boston Globe c...|[boston, globe, c...|\n",
      "|        0|   My phone can u...|[my, phone, can, ...|\n",
      "|        0|   hoping to see ...|[hoping, to, see,...|\n",
      "|        0|   i'm so cold th...|[im, so, cold, th...|\n",
      "|        0|   kinda but not ...|[kinda, but, not,...|\n",
      "|        0|   the batt to my...|[the, batt, to, m...|\n",
      "|        0|  *pout*  I want ...|[pout, i, want, s...|\n",
      "|        0|  2 orders to fil...|[orders, to, fill...|\n",
      "|        0|  Another expensi...|[another, expensi...|\n",
      "|        0|  Just got to wor...|[just, got, to, w...|\n",
      "|        0|  are there any p...|[are, there, any,...|\n",
      "|        0|  but chilli praw...|[but, chilli, pra...|\n",
      "|        0|  i was too slow ...|[i, was, too, slo...|\n",
      "|        0|  now the pic won...|[now, the, pic, w...|\n",
      "|        0|  some asshole go...|[some, asshole, g...|\n",
      "|        0| &quot;I'm giving...|[quotim, giving, ...|\n",
      "|        0| -strokes fake be...|[strokes, fake, b...|\n",
      "+---------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1343cde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320135, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9f0550",
   "metadata": {},
   "source": [
    "# Create an ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0a9147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peforms TF-IDF calculation and Logistic Regression\n",
    "remover = StopWordsRemover(inputCol=\"cleaned_data\", outputCol=\"words\")\n",
    "vector_tf = CountVectorizer(inputCol=\"words\", outputCol=\"tf\")\n",
    "idf = IDF(inputCol=\"tf\", outputCol=\"features\", minDocFreq=3)\n",
    "label_indexer = StringIndexer(inputCol = \"sentiment\", outputCol = \"label\")\n",
    "lr_model = LogisticRegression(maxIter=100)\n",
    "\n",
    "pipeline = Pipeline(stages=[remover, vector_tf, idf, label_indexer, lr_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cee402",
   "metadata": {},
   "source": [
    "# Fit the pipeline to the training dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf3895a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586f0484",
   "metadata": {},
   "source": [
    "# Predicting the test dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e083759f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sentiment: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- cleaned_data: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- tf: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label: double (nullable = false)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The labels are labelled with positive (4) as 0.0 \n",
    "negative (0) as 1.0\n",
    "'''\n",
    "prediction_df = trained_model.transform(test)\n",
    "prediction_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e51ef33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+----------+\n",
      "|             message|            features|label|prediction|\n",
      "+--------------------+--------------------+-----+----------+\n",
      "|       i really2 ...|(262144,[4,6,19,5...|  1.0|       1.0|\n",
      "|     jb isnt show...|(262144,[180,1157...|  1.0|       1.0|\n",
      "|    Not feeling i...|(262144,[7,55,99,...|  1.0|       1.0|\n",
      "|   Boston Globe c...|(262144,[72,1096,...|  1.0|       1.0|\n",
      "|   My phone can u...|(262144,[5,10,40,...|  1.0|       1.0|\n",
      "|   hoping to see ...|(262144,[20,177,1...|  1.0|       0.0|\n",
      "|   i'm so cold th...|(262144,[0,36,224...|  1.0|       1.0|\n",
      "|   kinda but not ...|(262144,[19,327],...|  1.0|       0.0|\n",
      "|   the batt to my...|(262144,[14,146,3...|  1.0|       1.0|\n",
      "|  *pout*  I want ...|(262144,[23,63,56...|  1.0|       1.0|\n",
      "|  2 orders to fil...|(262144,[1,5,56,6...|  1.0|       0.0|\n",
      "|  Another expensi...|(262144,[77,106,3...|  1.0|       1.0|\n",
      "|  Just got to wor...|(262144,[11,12,25...|  1.0|       0.0|\n",
      "|  are there any p...|(262144,[0,4,29,5...|  1.0|       1.0|\n",
      "|  but chilli praw...|(262144,[55,62,41...|  1.0|       1.0|\n",
      "|  i was too slow ...|(262144,[3,661,18...|  1.0|       1.0|\n",
      "|  now the pic won...|(262144,[40,97,32...|  1.0|       1.0|\n",
      "|  some asshole go...|(262144,[12,236,2...|  1.0|       1.0|\n",
      "| &quot;I'm giving...|(262144,[6,98,432...|  1.0|       0.0|\n",
      "| -strokes fake be...|(262144,[1531,537...|  1.0|       1.0|\n",
      "| .. yep,i have th...|(262144,[0,13,37,...|  1.0|       1.0|\n",
      "| .... Feeling pai...|(262144,[13,99,41...|  1.0|       1.0|\n",
      "| ..omg...my celly...|(262144,[3,501,88...|  1.0|       1.0|\n",
      "| 68 new results i...|(262144,[3,24,79,...|  1.0|       1.0|\n",
      "| ;( noooo! why? t...|(262144,[141,295,...|  1.0|       1.0|\n",
      "| @ coming to work...|(262144,[11,167,2...|  1.0|       1.0|\n",
      "| @kvetchingeditor...|(262144,[23,27,14...|  1.0|       1.0|\n",
      "| @lisad stopped t...|(262144,[374,1017...|  1.0|       0.0|\n",
      "| All my TV shows ...|(262144,[39,146,2...|  1.0|       1.0|\n",
      "| Alone and invisi...|(262144,[384,6248...|  1.0|       1.0|\n",
      "|         Am racit...|      (262144,[],[])|  1.0|       0.0|\n",
      "| Anyone have any ...|(262144,[57,265,8...|  1.0|       1.0|\n",
      "| BB is on again s...|(262144,[81,902,1...|  1.0|       1.0|\n",
      "| Body Of Missing ...|(262144,[177,213,...|  1.0|       1.0|\n",
      "| Boston and Atlan...|(262144,[407,658,...|  1.0|       0.0|\n",
      "| Climate Progress...|(262144,[990,2811...|  1.0|       1.0|\n",
      "| Dropping my mom ...|(262144,[44,239,4...|  1.0|       1.0|\n",
      "| Dt exam tomo ......|(262144,[328,6214...|  1.0|       1.0|\n",
      "|    FML &amp; my mom|(262144,[27,239,9...|  1.0|       1.0|\n",
      "| Help needed - Bl...|(262144,[138,406,...|  1.0|       0.0|\n",
      "| I FEEL SO..... R...|(262144,[43,3521]...|  1.0|       1.0|\n",
      "| I STILL CAN'T MA...|(262144,[10,22,55...|  1.0|       1.0|\n",
      "| I ate too much. ...|(262144,[10,31,43...|  1.0|       1.0|\n",
      "| I can't find one...|(262144,[0,10,17,...|  1.0|       1.0|\n",
      "| I can't go to sl...|(262144,[5,10,31,...|  1.0|       1.0|\n",
      "| I don't want her...|(262144,[6,23,240...|  1.0|       1.0|\n",
      "| I dunno what to ...|(262144,[981],[6....|  1.0|       1.0|\n",
      "| I feel alone rig...|(262144,[0,9,43,4...|  1.0|       1.0|\n",
      "| I feel down. I t...|(262144,[43,70,15...|  1.0|       1.0|\n",
      "| I guess porn bot...|(262144,[4,6,40,1...|  1.0|       1.0|\n",
      "| I hate Budapest ...|(262144,[70,956,1...|  1.0|       1.0|\n",
      "| I hate how every...|(262144,[9,70,108...|  1.0|       1.0|\n",
      "| I just found out...|(262144,[21,30,74...|  1.0|       1.0|\n",
      "| I need desprate ...|(262144,[33,138,2...|  1.0|       1.0|\n",
      "| I should've stay...|(262144,[29,1282,...|  1.0|       1.0|\n",
      "| I shoulda known....|(262144,[7,12,15,...|  1.0|       1.0|\n",
      "| I wanna pick up ...|(262144,[86,183,3...|  1.0|       0.0|\n",
      "| I want all my fr...|(262144,[14,23,51...|  1.0|       0.0|\n",
      "| I wish I could p...|(262144,[12,33,42...|  1.0|       1.0|\n",
      "| I wish there was...|(262144,[6,18,31,...|  1.0|       1.0|\n",
      "| I'm being confus...|(262144,[0,1080],...|  1.0|       1.0|\n",
      "| I'm having a shi...|(262144,[0,25,43,...|  1.0|       1.0|\n",
      "| I'm not going to...|(262144,[0,8,2410...|  1.0|       1.0|\n",
      "| I'm sick, very s...|(262144,[0,1,94],...|  1.0|       1.0|\n",
      "| I'm stuck in San...|(262144,[0,11,248...|  1.0|       1.0|\n",
      "| I'm such a lonel...|(262144,[0,821,14...|  1.0|       1.0|\n",
      "| Jay Leno's last ...|(262144,[34,91,18...|  1.0|       1.0|\n",
      "| Jonas Brothers 3...|(262144,[5,10,20,...|  1.0|       1.0|\n",
      "| M is bummed. i w...|(262144,[46,111,7...|  1.0|       1.0|\n",
      "| My head is hurti...|(262144,[2,10,174...|  1.0|       1.0|\n",
      "| Nugs fail to swe...|(262144,[29,196,5...|  1.0|       1.0|\n",
      "|          On duty...|(262144,[2439],[7...|  1.0|       0.0|\n",
      "|      PrinceCharming|(262144,[63669],[...|  1.0|       1.0|\n",
      "| RR had to win th...|(262144,[305,7509...|  1.0|       0.0|\n",
      "| Raiko's sick...w...|(262144,[771,990,...|  1.0|       1.0|\n",
      "| S just called to...|(262144,[18,21,53...|  1.0|       1.0|\n",
      "| Saturday in the ...|(262144,[156,320,...|  1.0|       1.0|\n",
      "| Season is over f...|(262144,[438,3124...|  1.0|       1.0|\n",
      "| She's gone for 2...|(262144,[230,259,...|  1.0|       1.0|\n",
      "| So sad @chp97 An...|(262144,[17,20,27...|  1.0|       1.0|\n",
      "| Sore throat! I h...|(262144,[19,50,21...|  1.0|       1.0|\n",
      "| Subscribe???  ww...|(262144,[5339],[9...|  1.0|       0.0|\n",
      "| The fam back on ...|(262144,[10,14,20...|  1.0|       1.0|\n",
      "| The guys put the...|(262144,[112,173,...|  1.0|       1.0|\n",
      "| The quote in the...|(262144,[3,39,125...|  1.0|       1.0|\n",
      "| Twitter wont eve...|(262144,[10,14,17...|  1.0|       1.0|\n",
      "| Uncle Ted is dea...|(262144,[496,1933...|  1.0|       1.0|\n",
      "| Updating product...|(262144,[12,215,1...|  1.0|       0.0|\n",
      "| WTF was I doing ...|(262144,[691],[12...|  1.0|       1.0|\n",
      "| When did Chris L...|(262144,[3,1121,1...|  1.0|       1.0|\n",
      "| Why do other pet...|(262144,[69,161,3...|  1.0|       0.0|\n",
      "| Wish the iPod ha...|(262144,[46,534,1...|  1.0|       1.0|\n",
      "| Wtf did you do? ...|(262144,[691,859]...|  1.0|       1.0|\n",
      "|       [UseYourLove]|      (262144,[],[])|  1.0|       0.0|\n",
      "| about 1/4 of my ...|(262144,[151,230,...|  1.0|       1.0|\n",
      "| ah I can't stop ...|(262144,[10,70,23...|  1.0|       1.0|\n",
      "| alex gaskarth is...|(262144,[5,20,37,...|  1.0|       1.0|\n",
      "|      ants are evil!|(262144,[1495,603...|  1.0|       1.0|\n",
      "| apple counting t...|(262144,[808,1805...|  1.0|       0.0|\n",
      "| apple counting t...|(262144,[808,1805...|  1.0|       0.0|\n",
      "+--------------------+--------------------+-----+----------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_df.select(\"message\",\"features\",\"label\",\"prediction\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5d90c21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                                      |\n",
      "+--------------------------------------------------------------------------------------------------------------+\n",
      "|(262144,[4,6,19,5432,182025],[3.0637558705620007,3.1999263774213245,3.5356513945264174,9.085532200495107,0.0])|\n",
      "+--------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_df.select(\"features\").show(1 , truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8473fd",
   "metadata": {},
   "source": [
    "# Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cc494af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8323899499569996\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "accuracy = evaluator.evaluate(prediction_df)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebfd8a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47713096575915465"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "regEval = RegressionEvaluator(predictionCol ='prediction', labelCol='label',metricName='rmse')\n",
    "regEval.evaluate(prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "724cf2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08938394704275376"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regEval_r2 = RegressionEvaluator(predictionCol ='prediction', labelCol='label',metricName='r2')\n",
    "regEval_r2.evaluate(prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d64a280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53ff255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d02f4450",
   "metadata": {},
   "source": [
    "# Save the pipeline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0faa8fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_model.save(\"fittedpipeline_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c412fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc398757",
   "metadata": {},
   "source": [
    "# Save the Model for Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6e62440",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.write()\\\n",
    "             .overwrite() \\\n",
    "             .save(\"ModelDir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03400f7a",
   "metadata": {},
   "source": [
    "# Load the Model Saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b923aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pickled model via pipeline api\n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "persistedModel = PipelineModel.load(\"ModelDir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2302089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predictionsDF = persistedModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49f81339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+----------+\n",
      "|             message|            features|label|prediction|\n",
      "+--------------------+--------------------+-----+----------+\n",
      "|       i really2 ...|(262144,[4,6,19,5...|  1.0|       1.0|\n",
      "|     jb isnt show...|(262144,[180,1157...|  1.0|       1.0|\n",
      "|    Not feeling i...|(262144,[7,55,99,...|  1.0|       1.0|\n",
      "|   Boston Globe c...|(262144,[72,1096,...|  1.0|       1.0|\n",
      "|   My phone can u...|(262144,[5,10,40,...|  1.0|       1.0|\n",
      "+--------------------+--------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionsDF.select(\"message\",\"features\",\"label\",\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8ece8c",
   "metadata": {},
   "source": [
    "# Thank you! Abdullah Abdelhakeem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
